{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from model_preparation import set_seed\n",
    "from data_preparation import _load_dataset, _prepare_data\n",
    "\n",
    "\n",
    "data_path = \"../data/train.csv\"\n",
    "model_name = 'microsoft/deberta-base'\n",
    "batch_size = 16\n",
    "create_validation_set = False\n",
    "SEED = 42\n",
    "\n",
    "set_seed(SEED)\n",
    "\n",
    "\n",
    "df = _load_dataset(data_path)\n",
    "\n",
    "df = df.iloc[:100]\n",
    "\n",
    "final_df = df[\"tweet\"].copy()\n",
    "\n",
    "pipeline = ['hyperlinks', 'mentions', 'hashtags', 'retweet', 'repetitions', 'emojis', 'smileys', 'spaces']\n",
    "df = _prepare_data(df, pipeline)\n",
    "\n",
    "df = pd.concat([final_df, df[[\"text\",\"label\"]]], axis = 1)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check spell on a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell\n",
    "\n",
    "def correct_spell(df: pd.DataFrame, attribute='text'):\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "    bigram_path = pkg_resources.resource_filename(\n",
    "        \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "    # term_index is the column of the term and count_index is the\n",
    "    # column of the term frequency\n",
    "    sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "\n",
    "    def check_spell(input_term):\n",
    "        # lookup suggestions for multi-word input strings (supports compound\n",
    "        # splitting & merging)\n",
    "        # max edit distance per lookup (per single word, not per whole input string)\n",
    "        suggestions = sym_spell.lookup_compound(input_term, max_edit_distance=2)\n",
    "        # display suggestion term, edit distance, and term frequency\n",
    "        progress_bar.update(1)\n",
    "        return suggestions[0]._term\n",
    "\n",
    "    progress_bar = tqdm(range(len(df[attribute])))\n",
    "    df[attribute+\"_spell\"] = df[attribute].map(check_spell)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = correct_spell(df = df, attribute = 'text')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords with nltk (but we can use spacy) + punctiation (this is not needed I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords', download_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "nltk.data.path.append(\"./\")\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "def clean_puntuation_stopwords(text):\n",
    "  text = ''.join([word for word in text if word not in string.punctuation])\n",
    "  text = text.lower()\n",
    "  text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "  return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_puntuation_stopwords)\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a97517a1f2e44bae43a0d1adced36113c0aa0bace4a2569b7d21fd338b4eff8a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
